{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3745a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\misaf\\DSC\\DSC 180A\\check_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a29585",
   "metadata": {},
   "source": [
    "## Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f81255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 412178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22176\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 23107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_data = load_dataset(\"code_search_net\", \"python\")\n",
    "python_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6fdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data for Python code only\n",
    "data_train = python_data['train']\n",
    "\n",
    "# if you would like a smaller dataset size\n",
    "# data_train = python_data['train][:10000]\n",
    "\n",
    "# convert Dataset --> DataFrame\n",
    "train_df = pd.DataFrame(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2334",
   "metadata": {},
   "source": [
    "## Step 1: Setting up ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5c9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "# es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580febd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the mappings (structure) for the python index\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        'repository_name': {\"type\": \"text\"}, \n",
    "        'func_path_in_repository': {\"type\": \"text\"}, \n",
    "        'func_name': {\"type\": \"text\"}, \n",
    "        'whole_func_string': {\"type\": \"text\"}, \n",
    "        'language': {\"type\": \"text\"}, \n",
    "        'func_code_string': {\"type\": \"text\"}, \n",
    "        'func_code_tokens': {\"type\": \"text\"}, \n",
    "        'func_documentation_string': {\"type\": \"text\"}, \n",
    "        'func_documentation_tokens': {\"type\": \"text\"}, \n",
    "        'split_name': {\"type\": \"text\"}, \n",
    "        'func_code_url': {\"type\": \"text\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "#analyzer settings\n",
    "analyzer_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"code_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\"],\n",
    "                    \"char_filter\": [\"symbol_char_filter\"]\n",
    "                }\n",
    "            },\n",
    "            \"char_filter\": {\n",
    "                \"symbol_char_filter\": {\n",
    "                    \"type\": \"mapping\",\n",
    "                    \"mappings\": [\n",
    "                        \"_=> \",    # Replace underscore with space\n",
    "                        \";=>\",     # Remove semicolons\n",
    "                        \"{=>\",     # Remove opening curly braces\n",
    "                        \"}=>\",     # Remove closing curly braces\n",
    "                        \")=>\",\n",
    "                        \"(=>\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0796db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the index named python with the mappings above\n",
    "# Will have an error if running more than once since indiced will already be created\n",
    "try:\n",
    "    es.indices.create(index=\"python\", mappings=mappings, body=analyzer_settings)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05441605",
   "metadata": {},
   "source": [
    "## Step 2: Adding Data into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c5b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read data into bulk_data: 138.64055919647217\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Creating a list of dictionaries with all the data to be added in to the ElasticSearch index\n",
    "bulk_data = []\n",
    "for i, row in enumerate(data_train):\n",
    "    bulk_data.append(\n",
    "        {\n",
    "            \"_index\": \"python\",\n",
    "            \"_id\": i,\n",
    "            \"_source\": {\n",
    "                \"repository_name\": row['repository_name'],\n",
    "                'func_path_in_repository': row['func_path_in_repository'], \n",
    "                'func_name': row['func_name'], \n",
    "                'whole_func_string': row['whole_func_string'], \n",
    "                'language': row['language'], \n",
    "                'func_code_string': row['func_code_string'], \n",
    "                'func_code_tokens': row['func_code_tokens'], \n",
    "                'func_documentation_string': row['func_documentation_string'], \n",
    "                'func_documentation_tokens': row['func_documentation_tokens'], \n",
    "                'split_name': row['split_name'], \n",
    "                'func_code_url': row['func_code_url']\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken to read data into bulk_data:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0fbbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to add data into the index: 310.7415289878845\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Adding data into the index\n",
    "bulk(es, bulk_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken to add data into the index:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a544f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListApiResponse([{'epoch': '1702307093', 'timestamp': '15:04:53', 'count': '412178'}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that all data has been read into the python index properly\n",
    "es.indices.refresh(index=\"python\")\n",
    "es.cat.count(index=\"python\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d55a3",
   "metadata": {},
   "source": [
    "## Step 3: Implementing the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31fb7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query, k=10):\n",
    "    \"\"\"\n",
    "    Searches the data using ElasticSearch to find the k most similar documents to the query.\n",
    "    Returns a list of the k most similar functions, along with their GitHub URLs and their similarity scores to the query\n",
    "    \"\"\"\n",
    "\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\n",
    "                            'repository_name',\n",
    "                            'func_path_in_repository',\n",
    "                            'func_name',\n",
    "                            'whole_func_string^3', #boost 3x\n",
    "                            'language',\n",
    "                            'func_code_string',\n",
    "                            'func_code_tokens^2', # boost 2x\n",
    "                            'func_documentation_string', \n",
    "                            'func_documentation_tokens',\n",
    "                            'split_name',\n",
    "                            'func_code_url'\n",
    "                        ],\n",
    "                        \"phrase_slop\": 2  # still considered a match if they are up to two terms apart\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": k\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=\"python\", body=es_query)\n",
    "    \n",
    "    results = []\n",
    "    # for each result, add the function name, the GitHub URL of the function, and the similarity score to the results list\n",
    "    for hit in response['hits']['hits']:\n",
    "        row = hit['_source']\n",
    "        results.append((row['func_name'], row['func_code_url'], hit['_score']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c6e2b",
   "metadata": {},
   "source": [
    "## Step 4: Testing the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31c0f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unique',\n",
       "  'https://github.com/odlgroup/odl/blob/b8443f6aca90e191ba36c91d32253c5a36249a6c/odl/util/utility.py#L1573-L1611',\n",
       "  45.621704),\n",
       " ('generate_random_sframe',\n",
       "  'https://github.com/apple/turicreate/blob/74514c3f99e25b46f22c6e02977fe3da69221c2e/src/unity/python/turicreate/util/_sframe_generation.py#L13-L71',\n",
       "  44.050896),\n",
       " ('unique',\n",
       "  'https://github.com/limix/numpy-sugar/blob/4bdfa26913135c76ef3cd542a332f4e5861e948b/numpy_sugar/_array.py#L132-L149',\n",
       "  43.924316),\n",
       " ('BaseProvider.random_sample',\n",
       "  'https://github.com/joke2k/faker/blob/965824b61132e52d92d1a6ce470396dbbe01c96c/faker/providers/__init__.py#L243-L248',\n",
       "  43.847404),\n",
       " ('unique',\n",
       "  'https://github.com/dedupeio/dedupe/blob/9f7c9f84473a4bcacf0f2b11152d8ed3eb35d48b/dedupe/labeler.py#L383-L390',\n",
       "  42.582573)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"unique elements\"\n",
    "es_search(query, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8dea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WHTTPCookieJar.import_header_text',\n",
       "  'https://github.com/a1ezzz/wasp-general/blob/1029839d33eb663f8dec76c1c46754d53c1de4a9/wasp_general/network/web/cookies.py#L316-L324',\n",
       "  46.92044),\n",
       " ('IIIFAuth.access_token',\n",
       "  'https://github.com/zimeon/iiif/blob/9d10018d01202fa2a76dfa61598dc6eca07b471f/iiif/auth.py#L257-L269',\n",
       "  46.747246),\n",
       " ('make_cookie',\n",
       "  'https://github.com/IdentityPython/pysaml2/blob/d3aa78eeb7d37c12688f783cb4db1c7263a14ad6/src/saml2/httputil.py#L320-L346',\n",
       "  45.509644)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create cookie\"\n",
    "es_search(query, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a282bb",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015b08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_query_python_es(query_list, k=10):\n",
    "    \"\"\"\n",
    "    Takes in a list of Python queries. Runs the search engine on those queries and returns\n",
    "    the top k results for that query\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    i = 1\n",
    "    \n",
    "    total_start = time.time()\n",
    "    for query in query_list:\n",
    "        # get top k results of query in our elastic search engine\n",
    "        query_search = es_search(query, k)\n",
    "        \n",
    "        # for each result of the query, add a row to test_results with\n",
    "        # the language (python), the query, and the GitHub Url to the result\n",
    "        for result in query_search:\n",
    "            # query_results = [\"python\", query, result[1]]\n",
    "            query_results = [\"python\", query, result[1], result[2]]\n",
    "            test_results.append(query_results)\n",
    "        \n",
    "        \n",
    "    total_end = time.time()\n",
    "    print(\"Time taken for all queries:\", total_end - total_start)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59449427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the annotated test dataset and get only the Python queries\n",
    "test_queries = pd.read_csv('annotation_store.csv')\n",
    "python_queries = test_queries[test_queries['Language'] == 'Python']\n",
    "\n",
    "query_list = python_queries['Query'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac289884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for all queries: 9.671287298202515\n"
     ]
    }
   ],
   "source": [
    "# run the tests for the evaluation data, return top 300 results for each\n",
    "test_es_results = run_test_query_python_es(query_list, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a805ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the test results as a Pandas DataFrame\n",
    "test_es_results_df = pd.DataFrame(test_es_results)\n",
    "test_es_results_df.columns=['language', 'query', 'url', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "948cde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model predictions to a csv file\n",
    "out = test_es_results_df[['language', 'query', 'url']]\n",
    "out.to_csv(\"predictions/es_model_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af61f90",
   "metadata": {},
   "source": [
    "**Simple Model (query_string search):**\n",
    "- Using 200 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.24%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.42%\n",
    "NDCG:\n",
    "        python: 0.355\n",
    "NDCG (full ranking):\n",
    "        python: 0.203\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb9123",
   "metadata": {},
   "source": [
    "**Improved Model (field boosting + analyzer )**\n",
    "- Using 300 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.75%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.76%\n",
    "NDCG:\n",
    "        python: 0.367\n",
    "NDCG (full ranking):\n",
    "        python: 0.202\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d590f6e",
   "metadata": {},
   "source": [
    "# Implementing LTR with LGBMRanker\n",
    "reference: https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6c294fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dfde8",
   "metadata": {},
   "source": [
    "## Step 1: Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c837b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cbe0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you would like to make the embeddings yourself (WARNING: MAY BE SLOW):\n",
    "# code_tokens = [sentence_transformer.encode(train_df['func_code_string'][i], convert_to_tensor=True) for i in range(len(train_df))]\n",
    "# docu_tokens = [sentence_transformer.encode(train_df['func_documentation_string'][i], convert_to_tensor=True) for i in range(len(train_df))]\n",
    "\n",
    "# otherwise can load in embeddings:\n",
    "with open('python_train_code_tokens.pkl', 'rb') as f:\n",
    "    code_tokens = pickle.load(f)\n",
    "    \n",
    "with open('python_train_docu_tokens.pkl', 'rb') as f:\n",
    "    docu_tokens = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e5797eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(q):\n",
    "    \"\"\"\n",
    "    Given an input, encodes it using the sentence_transformer.\n",
    "    Returns a tensor vector representation of the input.\n",
    "    \"\"\"\n",
    "    encoded = sentence_transformer.encode(q, convert_to_tensor=True)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "988b6e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository_name</th>\n",
       "      <th>func_path_in_repository</th>\n",
       "      <th>func_name</th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>language</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>split_name</th>\n",
       "      <th>func_code_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>train</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>python</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifi...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>predict</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>python</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>examples/face_recognition_knn.py</td>\n",
       "      <td>show_prediction_labels_on_image</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>python</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visua...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>_rect_to_css</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>python</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ageitgey/face_recognition</td>\n",
       "      <td>face_recognition/api.py</td>\n",
       "      <td>_trim_css_to_bounds</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>python</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bott...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/ageitgey/face_recognition/b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             repository_name           func_path_in_repository  \\\n",
       "0  ageitgey/face_recognition  examples/face_recognition_knn.py   \n",
       "1  ageitgey/face_recognition  examples/face_recognition_knn.py   \n",
       "2  ageitgey/face_recognition  examples/face_recognition_knn.py   \n",
       "3  ageitgey/face_recognition           face_recognition/api.py   \n",
       "4  ageitgey/face_recognition           face_recognition/api.py   \n",
       "\n",
       "                         func_name  \\\n",
       "0                            train   \n",
       "1                          predict   \n",
       "2  show_prediction_labels_on_image   \n",
       "3                     _rect_to_css   \n",
       "4              _trim_css_to_bounds   \n",
       "\n",
       "                                   whole_func_string language  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   python   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   python   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   python   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   python   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   python   \n",
       "\n",
       "                                    func_code_string  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                           func_documentation_tokens split_name  \\\n",
       "0  [Trains, a, k, -, nearest, neighbors, classifi...      train   \n",
       "1  [Recognizes, faces, in, given, image, using, a...      train   \n",
       "2  [Shows, the, face, recognition, results, visua...      train   \n",
       "3  [Convert, a, dlib, rect, object, to, a, plain,...      train   \n",
       "4  [Make, sure, a, tuple, in, (, top, right, bott...      train   \n",
       "\n",
       "                                       func_code_url  \n",
       "0  https://github.com/ageitgey/face_recognition/b...  \n",
       "1  https://github.com/ageitgey/face_recognition/b...  \n",
       "2  https://github.com/ageitgey/face_recognition/b...  \n",
       "3  https://github.com/ageitgey/face_recognition/b...  \n",
       "4  https://github.com/ageitgey/face_recognition/b...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba399b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the embeddings\n",
    "train_df['code_token'] = code_tokens.values()\n",
    "train_df['docu_token'] = docu_tokens.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca8ad685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>func_code_url</th>\n",
       "      <th>code_token</th>\n",
       "      <th>docu_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/pyviz/holoviews/blob/ae0dd2...</td>\n",
       "      <td>95.277590</td>\n",
       "      <td>https://github.com/pyviz/holoviews/blob/ae0dd2...</td>\n",
       "      <td>[tensor(-0.0594), tensor(0.0142), tensor(-0.04...</td>\n",
       "      <td>[tensor(-0.0302), tensor(0.0654), tensor(-0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/google/prettytensor/blob/75...</td>\n",
       "      <td>91.741930</td>\n",
       "      <td>https://github.com/google/prettytensor/blob/75...</td>\n",
       "      <td>[tensor(0.0362), tensor(0.0141), tensor(-0.079...</td>\n",
       "      <td>[tensor(0.0491), tensor(0.0401), tensor(-0.064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/rkday/nose2dep/blob/135a529...</td>\n",
       "      <td>84.326645</td>\n",
       "      <td>https://github.com/rkday/nose2dep/blob/135a529...</td>\n",
       "      <td>[tensor(-0.0707), tensor(0.0311), tensor(-0.05...</td>\n",
       "      <td>[tensor(-0.0843), tensor(0.0162), tensor(-0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/Zitrax/nose-dep/blob/fd29c9...</td>\n",
       "      <td>82.950325</td>\n",
       "      <td>https://github.com/Zitrax/nose-dep/blob/fd29c9...</td>\n",
       "      <td>[tensor(0.0173), tensor(-0.0341), tensor(0.009...</td>\n",
       "      <td>[tensor(0.0289), tensor(-0.0360), tensor(0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/bcbio/bcbio-nextgen/blob/6a...</td>\n",
       "      <td>80.839130</td>\n",
       "      <td>https://github.com/bcbio/bcbio-nextgen/blob/6a...</td>\n",
       "      <td>[tensor(0.0325), tensor(-0.0050), tensor(-0.02...</td>\n",
       "      <td>[tensor(0.0463), tensor(-0.0255), tensor(-0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                              query  \\\n",
       "0   python  sorting multiple arrays based on another array...   \n",
       "1   python  sorting multiple arrays based on another array...   \n",
       "2   python  sorting multiple arrays based on another array...   \n",
       "3   python  sorting multiple arrays based on another array...   \n",
       "4   python  sorting multiple arrays based on another array...   \n",
       "\n",
       "                                                 url      score  \\\n",
       "0  https://github.com/pyviz/holoviews/blob/ae0dd2...  95.277590   \n",
       "1  https://github.com/google/prettytensor/blob/75...  91.741930   \n",
       "2  https://github.com/rkday/nose2dep/blob/135a529...  84.326645   \n",
       "3  https://github.com/Zitrax/nose-dep/blob/fd29c9...  82.950325   \n",
       "4  https://github.com/bcbio/bcbio-nextgen/blob/6a...  80.839130   \n",
       "\n",
       "                                       func_code_url  \\\n",
       "0  https://github.com/pyviz/holoviews/blob/ae0dd2...   \n",
       "1  https://github.com/google/prettytensor/blob/75...   \n",
       "2  https://github.com/rkday/nose2dep/blob/135a529...   \n",
       "3  https://github.com/Zitrax/nose-dep/blob/fd29c9...   \n",
       "4  https://github.com/bcbio/bcbio-nextgen/blob/6a...   \n",
       "\n",
       "                                          code_token  \\\n",
       "0  [tensor(-0.0594), tensor(0.0142), tensor(-0.04...   \n",
       "1  [tensor(0.0362), tensor(0.0141), tensor(-0.079...   \n",
       "2  [tensor(-0.0707), tensor(0.0311), tensor(-0.05...   \n",
       "3  [tensor(0.0173), tensor(-0.0341), tensor(0.009...   \n",
       "4  [tensor(0.0325), tensor(-0.0050), tensor(-0.02...   \n",
       "\n",
       "                                          docu_token  \n",
       "0  [tensor(-0.0302), tensor(0.0654), tensor(-0.00...  \n",
       "1  [tensor(0.0491), tensor(0.0401), tensor(-0.064...  \n",
       "2  [tensor(-0.0843), tensor(0.0162), tensor(-0.06...  \n",
       "3  [tensor(0.0289), tensor(-0.0360), tensor(0.022...  \n",
       "4  [tensor(0.0463), tensor(-0.0255), tensor(-0.01...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to get the token representation of the ES results\n",
    "es_model_preds = test_es_results_df\n",
    "\n",
    "# match embeddings to the url of our ES results\n",
    "to_merge = train_df[['func_code_url', 'code_token', 'docu_token']]\n",
    "es_with_tokens = es_model_preds.merge(to_merge, left_on='url', right_on='func_code_url')\n",
    "es_with_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2571929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings of the queries\n",
    "queries = es_with_tokens['query'].unique()\n",
    "query_mapping = {q:parse_query(q) for q in queries}\n",
    "es_with_tokens['query_tokens'] = es_with_tokens['query'].map(query_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a3cd1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity function\n",
    "def cos_sim(tensor1, tensor2):\n",
    "    return cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n",
    "\n",
    "# get the cosine similarities for code and documentation\n",
    "es_with_tokens['code_similarity'] = es_with_tokens.apply(lambda row: cos_sim(row['query_tokens'], row['code_token']), axis=1)\n",
    "es_with_tokens['docu_similarity'] = es_with_tokens.apply(lambda row: cos_sim(row['query_tokens'], row['docu_token']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e74b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in relevance scores and creating a merged dataset\n",
    "relevance_scores = pd.read_csv(\"evaluation/annotation_store.csv\")\n",
    "\n",
    "#only working with Python\n",
    "python_rs = relevance_scores[relevance_scores['Language']=='Python']\n",
    "\n",
    "#merging and dropping irrelevant columns\n",
    "merged_scores = pd.merge(es_with_tokens, python_rs,  how='left', left_on=['query','url'], right_on = ['Query','GitHubUrl'])\n",
    "merged_scores = merged_scores.drop(columns=['Language', 'Query', 'GitHubUrl', 'Notes'])\n",
    "\n",
    "#search results that were not in the relevance csv get a relevance score of 0\n",
    "merged_scores['Relevance'] = merged_scores['Relevance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5259d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have queries grouped together for our ranking model\n",
    "merged_scores = merged_scores.sort_values(by=[\"query\"], ascending=[True])\n",
    "\n",
    "# our feature will be the relevance score our es model returns\n",
    "X = merged_scores[['score', 'code_similarity', 'docu_similarity']]\n",
    "y = merged_scores['Relevance']\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False, random_state=11)\n",
    "train_groups = merged_scores.iloc[:len(X_train)].groupby('query').size().to_numpy()\n",
    "test_groups = merged_scores.iloc[len(X_train):].groupby('query').size().to_numpy()\n",
    "\n",
    "#checking lengths match up\n",
    "assert len(X_train) == sum(train_groups)\n",
    "assert len(X_test) == sum(test_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9621dc",
   "metadata": {},
   "source": [
    "## Step 2: Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565fc89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 27051, number of used features: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(metric='ndcg', objective='lambdarank')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\")\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train, y_train, group=train_groups, eval_set=[(X_test,y_test)],eval_group=[test_groups],eval_metric=['ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7abc8",
   "metadata": {},
   "source": [
    "## Step 3: Using the Model to Edit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1e7dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>func_code_url</th>\n",
       "      <th>code_token</th>\n",
       "      <th>docu_token</th>\n",
       "      <th>query_tokens</th>\n",
       "      <th>code_similarity</th>\n",
       "      <th>docu_similarity</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>adjusted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/emory-libraries/eulfedora/b...</td>\n",
       "      <td>26.646240</td>\n",
       "      <td>https://github.com/emory-libraries/eulfedora/b...</td>\n",
       "      <td>[tensor(-0.0138), tensor(0.0153), tensor(-0.00...</td>\n",
       "      <td>[tensor(-0.0269), tensor(0.0363), tensor(-0.03...</td>\n",
       "      <td>[tensor(-0.0402), tensor(0.0566), tensor(-0.03...</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.201495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/UCL-INGI/INGInious/blob/cbd...</td>\n",
       "      <td>36.234085</td>\n",
       "      <td>https://github.com/UCL-INGI/INGInious/blob/cbd...</td>\n",
       "      <td>[tensor(0.0086), tensor(0.0712), tensor(-0.080...</td>\n",
       "      <td>[tensor(-0.0148), tensor(0.0829), tensor(-0.04...</td>\n",
       "      <td>[tensor(-0.0402), tensor(0.0566), tensor(-0.03...</td>\n",
       "      <td>-0.034489</td>\n",
       "      <td>-0.022924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.807974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/saltstack/salt/blob/e8541fd...</td>\n",
       "      <td>36.123787</td>\n",
       "      <td>https://github.com/saltstack/salt/blob/e8541fd...</td>\n",
       "      <td>[tensor(0.0209), tensor(-0.1407), tensor(-0.01...</td>\n",
       "      <td>[tensor(0.0332), tensor(-0.1304), tensor(-0.04...</td>\n",
       "      <td>[tensor(-0.0402), tensor(0.0566), tensor(-0.03...</td>\n",
       "      <td>-0.060270</td>\n",
       "      <td>-0.096251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.500716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/UCSBarchlab/PyRTL/blob/0988...</td>\n",
       "      <td>36.123787</td>\n",
       "      <td>https://github.com/UCSBarchlab/PyRTL/blob/0988...</td>\n",
       "      <td>[tensor(-0.0091), tensor(0.0212), tensor(-0.12...</td>\n",
       "      <td>[tensor(-0.0562), tensor(0.0040), tensor(-0.06...</td>\n",
       "      <td>[tensor(-0.0402), tensor(0.0566), tensor(-0.03...</td>\n",
       "      <td>-0.005832</td>\n",
       "      <td>0.048360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.343052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/openid/JWTConnect-Python-Cr...</td>\n",
       "      <td>35.897980</td>\n",
       "      <td>https://github.com/openid/JWTConnect-Python-Cr...</td>\n",
       "      <td>[tensor(0.0162), tensor(0.0723), tensor(-0.030...</td>\n",
       "      <td>[tensor(0.0249), tensor(-0.0223), tensor(-0.03...</td>\n",
       "      <td>[tensor(-0.0402), tensor(0.0566), tensor(-0.03...</td>\n",
       "      <td>-0.027712</td>\n",
       "      <td>-0.053528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.132794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language           query  \\\n",
       "5193   python  aes encryption   \n",
       "4923   python  aes encryption   \n",
       "4924   python  aes encryption   \n",
       "4926   python  aes encryption   \n",
       "4928   python  aes encryption   \n",
       "\n",
       "                                                    url      score  \\\n",
       "5193  https://github.com/emory-libraries/eulfedora/b...  26.646240   \n",
       "4923  https://github.com/UCL-INGI/INGInious/blob/cbd...  36.234085   \n",
       "4924  https://github.com/saltstack/salt/blob/e8541fd...  36.123787   \n",
       "4926  https://github.com/UCSBarchlab/PyRTL/blob/0988...  36.123787   \n",
       "4928  https://github.com/openid/JWTConnect-Python-Cr...  35.897980   \n",
       "\n",
       "                                          func_code_url  \\\n",
       "5193  https://github.com/emory-libraries/eulfedora/b...   \n",
       "4923  https://github.com/UCL-INGI/INGInious/blob/cbd...   \n",
       "4924  https://github.com/saltstack/salt/blob/e8541fd...   \n",
       "4926  https://github.com/UCSBarchlab/PyRTL/blob/0988...   \n",
       "4928  https://github.com/openid/JWTConnect-Python-Cr...   \n",
       "\n",
       "                                             code_token  \\\n",
       "5193  [tensor(-0.0138), tensor(0.0153), tensor(-0.00...   \n",
       "4923  [tensor(0.0086), tensor(0.0712), tensor(-0.080...   \n",
       "4924  [tensor(0.0209), tensor(-0.1407), tensor(-0.01...   \n",
       "4926  [tensor(-0.0091), tensor(0.0212), tensor(-0.12...   \n",
       "4928  [tensor(0.0162), tensor(0.0723), tensor(-0.030...   \n",
       "\n",
       "                                             docu_token  \\\n",
       "5193  [tensor(-0.0269), tensor(0.0363), tensor(-0.03...   \n",
       "4923  [tensor(-0.0148), tensor(0.0829), tensor(-0.04...   \n",
       "4924  [tensor(0.0332), tensor(-0.1304), tensor(-0.04...   \n",
       "4926  [tensor(-0.0562), tensor(0.0040), tensor(-0.06...   \n",
       "4928  [tensor(0.0249), tensor(-0.0223), tensor(-0.03...   \n",
       "\n",
       "                                           query_tokens  code_similarity  \\\n",
       "5193  [tensor(-0.0402), tensor(0.0566), tensor(-0.03...         0.044184   \n",
       "4923  [tensor(-0.0402), tensor(0.0566), tensor(-0.03...        -0.034489   \n",
       "4924  [tensor(-0.0402), tensor(0.0566), tensor(-0.03...        -0.060270   \n",
       "4926  [tensor(-0.0402), tensor(0.0566), tensor(-0.03...        -0.005832   \n",
       "4928  [tensor(-0.0402), tensor(0.0566), tensor(-0.03...        -0.027712   \n",
       "\n",
       "      docu_similarity  Relevance  adjusted_score  \n",
       "5193        -0.000421        0.0       -4.201495  \n",
       "4923        -0.022924        0.0       -2.807974  \n",
       "4924        -0.096251        0.0       -4.500716  \n",
       "4926         0.048360        0.0       -4.343052  \n",
       "4928        -0.053528        0.0       -4.132794  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the model to predict an adjusted score\n",
    "merged_scores['adjusted_score'] = model.predict(merged_scores[['score', 'code_similarity', 'docu_similarity']])\n",
    "merged_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa946542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the results that have an adjusted score above the threshold (found through trial and error)\n",
    "thresh = -0.75\n",
    "new_preds = merged_scores[(merged_scores['adjusted_score'] >= thresh)]\n",
    "\n",
    "#output results\n",
    "new_preds[['language', 'query', 'url']].to_csv('predictions/ltr_es_model_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f00867",
   "metadata": {},
   "source": [
    "### ElasticSearch + LTR\n",
    "threshold = -0.75\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 20.32%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 21.39%\n",
    "NDCG:\n",
    "        python: 0.438\n",
    "NDCG (full ranking):\n",
    "        python: 0.241\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff560047",
   "metadata": {},
   "source": [
    "### Elasticsearch with Cosim Sim (both) + LTR\n",
    "threshold = -0.75\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 23.05%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 25.37%\n",
    "NDCG:\n",
    "        python: 0.549\n",
    "NDCG (full ranking):\n",
    "        python: 0.408\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
