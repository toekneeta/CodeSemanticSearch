{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3745a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a29585",
   "metadata": {},
   "source": [
    "## Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f81255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 412178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22176\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 23107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_data = load_dataset(\"code_search_net\", \"python\")\n",
    "python_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6fdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data for Python code only\n",
    "data_train = python_data['train']\n",
    "data_train_snippet = data_train['whole_func_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2334",
   "metadata": {},
   "source": [
    "## Step 1: Setting up ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5c9a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '8dfd8d5f67dd',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': '3jzC3PX1R2SACsSjjagp6w',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580febd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the mappings (structure) for the python index\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        'repository_name': {\"type\": \"text\"}, \n",
    "        'func_path_in_repository': {\"type\": \"text\"}, \n",
    "        'func_name': {\"type\": \"text\"}, \n",
    "        'whole_func_string': {\"type\": \"text\"}, \n",
    "        'language': {\"type\": \"text\"}, \n",
    "        'func_code_string': {\"type\": \"text\"}, \n",
    "        'func_code_tokens': {\"type\": \"text\"}, \n",
    "        'func_documentation_string': {\"type\": \"text\"}, \n",
    "        'func_documentation_tokens': {\"type\": \"text\"}, \n",
    "        'split_name': {\"type\": \"text\"}, \n",
    "        'func_code_url': {\"type\": \"text\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "#analyzer settings\n",
    "analyzer_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"code_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\"],\n",
    "                    \"char_filter\": [\"symbol_char_filter\"]\n",
    "                }\n",
    "            },\n",
    "            \"char_filter\": {\n",
    "                \"symbol_char_filter\": {\n",
    "                    \"type\": \"mapping\",\n",
    "                    \"mappings\": [\n",
    "                        \"_=> \",    # Replace underscore with space\n",
    "                        \";=>\",     # Remove semicolons\n",
    "                        \"{=>\",     # Remove opening curly braces\n",
    "                        \"}=>\",     # Remove closing curly braces\n",
    "                        \")=>\",\n",
    "                        \"(=>\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0796db5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [python/_lKLwfeiRP2DUYz6EyT7bA] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\misaf\\Documents\\DSC 180A\\CodeSemanticSearch\\elastic_search_engine.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misaf/Documents/DSC%20180A/CodeSemanticSearch/elastic_search_engine.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating the index python with the mappings above\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/misaf/Documents/DSC%20180A/CodeSemanticSearch/elastic_search_engine.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m es\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mcreate(index\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m\"\u001b[39;49m, mappings\u001b[39m=\u001b[39;49mmappings, body\u001b[39m=\u001b[39;49manalyzer_settings)\n",
      "File \u001b[1;32mc:\\Users\\misaf\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:402\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\misaf\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\elasticsearch\\_sync\\client\\indices.py:493\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[1;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mif\u001b[39;00m __body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     __headers[\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m    494\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers, body\u001b[39m=\u001b[39;49m__body\n\u001b[0;32m    495\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\misaf\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:389\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_request\u001b[39m(\n\u001b[0;32m    379\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    380\u001b[0m     method: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[39m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[39m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    390\u001b[0m         method, path, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody\n\u001b[0;32m    391\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\misaf\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    318\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[0;32m    321\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[0;32m    326\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [python/_lKLwfeiRP2DUYz6EyT7bA] already exists')"
     ]
    }
   ],
   "source": [
    "# Creating the index python with the mappings above\n",
    "es.indices.create(index=\"python\", mappings=mappings, body=analyzer_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05441605",
   "metadata": {},
   "source": [
    "## Step 2: Adding Data into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c5b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read data into bulk_data: 191.51014494895935\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Creating a list of dictionaries with all the data to be added in to the ElasticSearch index\n",
    "bulk_data = []\n",
    "for i, row in enumerate(data_train):\n",
    "    bulk_data.append(\n",
    "        {\n",
    "            \"_index\": \"python\",\n",
    "            \"_id\": i,\n",
    "            \"_source\": {\n",
    "                \"repository_name\": row['repository_name'],\n",
    "                'func_path_in_repository': row['func_path_in_repository'], \n",
    "                'func_name': row['func_name'], \n",
    "                'whole_func_string': row['whole_func_string'], \n",
    "                'language': row['language'], \n",
    "                'func_code_string': row['func_code_string'], \n",
    "                'func_code_tokens': row['func_code_tokens'], \n",
    "                'func_documentation_string': row['func_documentation_string'], \n",
    "                'func_documentation_tokens': row['func_documentation_tokens'], \n",
    "                'split_name': row['split_name'], \n",
    "                'func_code_url': row['func_code_url']\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken to read data into bulk_data:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0fbbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to add data into the index: 527.269453048706\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Adding data into the index\n",
    "bulk(es, bulk_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken to add data into the index:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a544f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListApiResponse([{'epoch': '1700604381', 'timestamp': '22:06:21', 'count': '412178'}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that all data has been read into the python index properly\n",
    "es.indices.refresh(index=\"python\")\n",
    "es.cat.count(index=\"python\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d55a3",
   "metadata": {},
   "source": [
    "## Step 3: Implementing the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31fb7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query, k=10):\n",
    "    \"\"\"\n",
    "    Searches the data using ElasticSearch to find the k most similar documents to the query.\n",
    "    Returns a list of the k most similar functions, along with their GitHub URLs and their similarity scores to the query\n",
    "    \"\"\"\n",
    "\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\n",
    "                            'repository_name',\n",
    "                            'func_path_in_repository',\n",
    "                            'func_name',\n",
    "                            'whole_func_string^3', #boost\n",
    "                            'language',\n",
    "                            'func_code_string',\n",
    "                            'func_code_tokens^2', # boost\n",
    "                            'func_documentation_string',\n",
    "                            'func_documentation_tokens',\n",
    "                            'split_name',\n",
    "                            'func_code_url'\n",
    "                        ],\n",
    "                        \"phrase_slop\": 2  # allows for flexibility in phrase matching\n",
    "                    }\n",
    "                },\n",
    "                \"should\": [\n",
    "                    {\"match_phrase\": {\"func_name\": {\"query\": query, \"boost\": 2}}},\n",
    "                    {\"match_phrase\": {\"whole_func_string\": {\"query\": query, \"boost\": 3}}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": k\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=\"python\", body=es_query)\n",
    "    \n",
    "    results = []\n",
    "    # for each result, add the function name, the GitHub URL of the function, and the similarity score to the results list\n",
    "    for hit in response['hits']['hits']:\n",
    "        row = hit['_source']\n",
    "        results.append((row['func_name'], row['func_code_url'], hit['_score']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c6e2b",
   "metadata": {},
   "source": [
    "## Step 4: Testing the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e31c0f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unique',\n",
       "  'https://github.com/odlgroup/odl/blob/b8443f6aca90e191ba36c91d32253c5a36249a6c/odl/util/utility.py#L1573-L1611',\n",
       "  45.621704),\n",
       " ('generate_random_sframe',\n",
       "  'https://github.com/apple/turicreate/blob/74514c3f99e25b46f22c6e02977fe3da69221c2e/src/unity/python/turicreate/util/_sframe_generation.py#L13-L71',\n",
       "  44.050896),\n",
       " ('unique',\n",
       "  'https://github.com/limix/numpy-sugar/blob/4bdfa26913135c76ef3cd542a332f4e5861e948b/numpy_sugar/_array.py#L132-L149',\n",
       "  43.924316),\n",
       " ('BaseProvider.random_sample',\n",
       "  'https://github.com/joke2k/faker/blob/965824b61132e52d92d1a6ce470396dbbe01c96c/faker/providers/__init__.py#L243-L248',\n",
       "  43.847404),\n",
       " ('unique',\n",
       "  'https://github.com/dedupeio/dedupe/blob/9f7c9f84473a4bcacf0f2b11152d8ed3eb35d48b/dedupe/labeler.py#L383-L390',\n",
       "  42.582573)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"unique elements\"\n",
    "es_search(query, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '8dfd8d5f67dd', 'cluster_name': 'docker-cluster', 'cluster_uuid': '3jzC3PX1R2SACsSjjagp6w', 'version': {'number': '8.7.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '09520b59b6bc1057340b55750186466ea715e30e', 'build_date': '2023-03-27T16:31:09.816451435Z', 'build_snapshot': False, 'lucene_version': '9.5.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3a8dea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WHTTPCookieJar.import_header_text',\n",
       "  'https://github.com/a1ezzz/wasp-general/blob/1029839d33eb663f8dec76c1c46754d53c1de4a9/wasp_general/network/web/cookies.py#L316-L324',\n",
       "  46.92044),\n",
       " ('IIIFAuth.access_token',\n",
       "  'https://github.com/zimeon/iiif/blob/9d10018d01202fa2a76dfa61598dc6eca07b471f/iiif/auth.py#L257-L269',\n",
       "  46.747246),\n",
       " ('make_cookie',\n",
       "  'https://github.com/IdentityPython/pysaml2/blob/d3aa78eeb7d37c12688f783cb4db1c7263a14ad6/src/saml2/httputil.py#L320-L346',\n",
       "  45.509644)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create cookie\"\n",
    "es_search(query, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a282bb",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "015b08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_query_python_es(query_list, k=10):\n",
    "    \"\"\"\n",
    "    Takes in a list of Python queries. Runs the search engine on those queries and returns\n",
    "    the top k results for that query\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    i = 1\n",
    "    \n",
    "    total_start = time.time()\n",
    "    for query in query_list:\n",
    "        # get top k results of query in our elastic search engine\n",
    "        query_search = es_search(query, k)\n",
    "        \n",
    "        # for each result of the query, add a row to test_results with\n",
    "        # the language (python), the query, and the GitHub Url to the result\n",
    "        for result in query_search:\n",
    "            query_results = [\"python\", query, result[1]]\n",
    "            test_results.append(query_results)\n",
    "        \n",
    "        \n",
    "    total_end = time.time()\n",
    "    print(\"Time taken for all queries:\", total_end - total_start)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59449427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the annotated test dataset and get only the Python queries\n",
    "test_queries = pd.read_csv('annotation_store.csv')\n",
    "python_queries = test_queries[test_queries['Language'] == 'Python']\n",
    "\n",
    "query_list = python_queries['Query'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac289884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for all queries: 8.889116287231445\n"
     ]
    }
   ],
   "source": [
    "# run the tests for the evaluation data\n",
    "test_es_results = run_test_query_python_es(query_list, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a7a805ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/pyviz/holoviews/blob/ae0dd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/google/prettytensor/blob/75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/rkday/nose2dep/blob/135a529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/Zitrax/nose-dep/blob/fd29c9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/bcbio/bcbio-nextgen/blob/6a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29695</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/acutesoftware/AIKIF/blob/fc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29696</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/PlaidWeb/Publ/blob/ce789363...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29697</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/Phyks/libbmc/blob/9ef1a29d2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/DS-100/nb-to-gradescope/blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29699</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/slinderman/pypolyagamma/blo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29700 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language                                              query  \\\n",
       "0       python  sorting multiple arrays based on another array...   \n",
       "1       python  sorting multiple arrays based on another array...   \n",
       "2       python  sorting multiple arrays based on another array...   \n",
       "3       python  sorting multiple arrays based on another array...   \n",
       "4       python  sorting multiple arrays based on another array...   \n",
       "...        ...                                                ...   \n",
       "29695   python                                convert html to pdf   \n",
       "29696   python                                convert html to pdf   \n",
       "29697   python                                convert html to pdf   \n",
       "29698   python                                convert html to pdf   \n",
       "29699   python                                convert html to pdf   \n",
       "\n",
       "                                                     url  \n",
       "0      https://github.com/pyviz/holoviews/blob/ae0dd2...  \n",
       "1      https://github.com/google/prettytensor/blob/75...  \n",
       "2      https://github.com/rkday/nose2dep/blob/135a529...  \n",
       "3      https://github.com/Zitrax/nose-dep/blob/fd29c9...  \n",
       "4      https://github.com/bcbio/bcbio-nextgen/blob/6a...  \n",
       "...                                                  ...  \n",
       "29695  https://github.com/acutesoftware/AIKIF/blob/fc...  \n",
       "29696  https://github.com/PlaidWeb/Publ/blob/ce789363...  \n",
       "29697  https://github.com/Phyks/libbmc/blob/9ef1a29d2...  \n",
       "29698  https://github.com/DS-100/nb-to-gradescope/blo...  \n",
       "29699  https://github.com/slinderman/pypolyagamma/blo...  \n",
       "\n",
       "[29700 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the test results as a Pandas DataFrame\n",
    "test_es_results_df = pd.DataFrame(test_es_results)\n",
    "test_es_results_df = test_es_results_df.rename(columns={0: \"language\", 1: \"query\", 2: \"url\"})\n",
    "test_es_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "948cde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model predictions to a csv file\n",
    "test_es_results_df.to_csv(\"es_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af61f90",
   "metadata": {},
   "source": [
    "**Simple Model (query_string search):**\n",
    "- Using 200 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.24%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.42%\n",
    "NDCG:\n",
    "        python: 0.355\n",
    "NDCG (full ranking):\n",
    "        python: 0.203\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved Model (field boosting + analyzer)\n",
    "- Using 300 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.75%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.76%\n",
    "NDCG:\n",
    "        python: 0.373\n",
    "NDCG (full ranking):\n",
    "        python: 0.196\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved Model (field boosting + analyzer with 'should' statement removed)**\n",
    "- Using 300 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.75%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.76%\n",
    "NDCG:\n",
    "        python: 0.367\n",
    "NDCG (full ranking):\n",
    "        python: 0.202\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
