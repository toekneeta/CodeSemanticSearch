{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3745a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a29585",
   "metadata": {},
   "source": [
    "## Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f81255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 412178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22176\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 23107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_data = load_dataset(\"code_search_net\", \"python\")\n",
    "python_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6fdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data for Python code only\n",
    "data_train = python_data['train']\n",
    "data_train_snippet = data_train['whole_func_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2334",
   "metadata": {},
   "source": [
    "## Step 1: Setting up ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5c9a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '02982a8770ec',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'TeGH1jOWT2OmsX5S9hiisA',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580febd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the mappings (structure) for the python index\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        'repository_name': {\"type\": \"text\"}, \n",
    "        'func_path_in_repository': {\"type\": \"text\"}, \n",
    "        'func_name': {\"type\": \"text\"}, \n",
    "        'whole_func_string': {\"type\": \"text\"}, \n",
    "        'language': {\"type\": \"text\"}, \n",
    "        'func_code_string': {\"type\": \"text\"}, \n",
    "        'func_code_tokens': {\"type\": \"text\"}, \n",
    "        'func_documentation_string': {\"type\": \"text\"}, \n",
    "        'func_documentation_tokens': {\"type\": \"text\"}, \n",
    "        'split_name': {\"type\": \"text\"}, \n",
    "        'func_code_url': {\"type\": \"text\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0796db5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'python'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the index python with the mappings above\n",
    "es.indices.create(index=\"python\", mappings=mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05441605",
   "metadata": {},
   "source": [
    "## Step 2: Adding Data into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c5b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read data into bulk_data: 344.7798068523407\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Creating a list of dictionaries with all the data to be added in to the ElasticSearch index\n",
    "bulk_data = []\n",
    "for i, row in enumerate(data_train):\n",
    "    bulk_data.append(\n",
    "        {\n",
    "            \"_index\": \"python\",\n",
    "            \"_id\": i,\n",
    "            \"_source\": {\n",
    "                \"repository_name\": row['repository_name'],\n",
    "                'func_path_in_repository': row['func_path_in_repository'], \n",
    "                'func_name': row['func_name'], \n",
    "                'whole_func_string': row['whole_func_string'], \n",
    "                'language': row['language'], \n",
    "                'func_code_string': row['func_code_string'], \n",
    "                'func_code_tokens': row['func_code_tokens'], \n",
    "                'func_documentation_string': row['func_documentation_string'], \n",
    "                'func_documentation_tokens': row['func_documentation_tokens'], \n",
    "                'split_name': row['split_name'], \n",
    "                'func_code_url': row['func_code_url']\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken to read data into bulk_data:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0fbbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to add data into the index: 305.79853415489197\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Adding data into the index\n",
    "bulk(es, bulk_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken to add data into the index:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a544f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListApiResponse([{'epoch': '1699932894', 'timestamp': '03:34:54', 'count': '412178'}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that all data has been read into the python index properly\n",
    "es.indices.refresh(index=\"python\")\n",
    "es.cat.count(index=\"python\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d55a3",
   "metadata": {},
   "source": [
    "## Step 3: Implementing the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31fb7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query, k=10):\n",
    "    \"\"\"\n",
    "    Searches the data using ElasticSearch to find the k most similar documents to the query.\n",
    "    Returns a list of the k most similar functions, along with their GitHub URLs and their similarity scores to the query\n",
    "    \"\"\"\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"query_string\": {\n",
    "                \"query\": query\n",
    "            }\n",
    "        },\n",
    "        \"size\": k\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=\"python\", body=es_query)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # for each result, add the function name, the GitHub URL of the function, and the similarity score to the results list\n",
    "    for hit in response['hits']['hits']:\n",
    "        row = hit['_source']\n",
    "        results.append((row['func_name'], row['func_code_url'], hit['_score']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c6e2b",
   "metadata": {},
   "source": [
    "## Step 4: Testing the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31c0f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BaseProvider.random_choices',\n",
       "  'https://github.com/joke2k/faker/blob/965824b61132e52d92d1a6ce470396dbbe01c96c/faker/providers/__init__.py#L207-L223',\n",
       "  16.35838),\n",
       " ('BaseProvider.random_sample',\n",
       "  'https://github.com/joke2k/faker/blob/965824b61132e52d92d1a6ce470396dbbe01c96c/faker/providers/__init__.py#L243-L248',\n",
       "  16.35838),\n",
       " ('unique',\n",
       "  'https://github.com/has2k1/plydata/blob/d8ca85ff70eee621e96f7c74034e90fec16e8b61/plydata/utils.py#L215-L256',\n",
       "  15.654947),\n",
       " ('unique',\n",
       "  'https://github.com/odlgroup/odl/blob/b8443f6aca90e191ba36c91d32253c5a36249a6c/odl/util/utility.py#L1573-L1611',\n",
       "  15.207234),\n",
       " ('unique_everseen',\n",
       "  'https://github.com/bsolomon1124/pyfinance/blob/c95925209a809b4e648e79cbeaf7711d8e5ff1a6/pyfinance/utils.py#L768-L776',\n",
       "  15.006733)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"unique elements\"\n",
    "es_search(query, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8dea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WHTTPCookieJar.import_header_text',\n",
       "  'https://github.com/a1ezzz/wasp-general/blob/1029839d33eb663f8dec76c1c46754d53c1de4a9/wasp_general/network/web/cookies.py#L316-L324',\n",
       "  16.109276),\n",
       " ('IIIFAuth.access_token',\n",
       "  'https://github.com/zimeon/iiif/blob/9d10018d01202fa2a76dfa61598dc6eca07b471f/iiif/auth.py#L257-L269',\n",
       "  15.582415),\n",
       " ('make_cookie',\n",
       "  'https://github.com/IdentityPython/pysaml2/blob/d3aa78eeb7d37c12688f783cb4db1c7263a14ad6/src/saml2/httputil.py#L320-L346',\n",
       "  15.16988)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create cookie\"\n",
    "es_search(query, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a282bb",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "015b08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_query_python_es(query_list, k=10):\n",
    "    \"\"\"\n",
    "    Takes in a list of Python queries. Runs the search engine on those queries and returns\n",
    "    the top k results for that query\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    i = 1\n",
    "    \n",
    "    total_start = time.time()\n",
    "    for query in query_list:\n",
    "        # get top k results of query in our elastic search engine\n",
    "        query_search = es_search(query, k)\n",
    "        \n",
    "        # for each result of the query, add a row to test_results with\n",
    "        # the language (python), the query, and the GitHub Url to the result\n",
    "        for result in query_search:\n",
    "            query_results = [\"python\", query, result[1]]\n",
    "            test_results.append(query_results)\n",
    "        \n",
    "        \n",
    "    total_end = time.time()\n",
    "    print(\"Time taken for all queries:\", total_end - total_start)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59449427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the annotated test dataset and get only the Python queries\n",
    "test_queries = pd.read_csv('annotation_store.csv')\n",
    "python_queries = test_queries[test_queries['Language'] == 'Python']\n",
    "\n",
    "query_list = python_queries['Query'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac289884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for all queries: 11.806987762451172\n"
     ]
    }
   ],
   "source": [
    "# run the tests for the evaluation data\n",
    "test_es_results = run_test_query_python_es(query_list, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7a805ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/pyviz/holoviews/blob/ae0dd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/google/prettytensor/blob/75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/rkday/nose2dep/blob/135a529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/Zitrax/nose-dep/blob/fd29c9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/lrq3000/pyFileFixity/blob/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29695</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/reingart/pyafipws/blob/ee87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29696</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/doakey3/DashTable/blob/744c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29697</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/chimera0/accel-brain-code/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/IndicoDataSolutions/IndicoI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29699</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/mrstephenneal/pdfconduit/bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language                                              query  \\\n",
       "0       python  sorting multiple arrays based on another array...   \n",
       "1       python  sorting multiple arrays based on another array...   \n",
       "2       python  sorting multiple arrays based on another array...   \n",
       "3       python  sorting multiple arrays based on another array...   \n",
       "4       python  sorting multiple arrays based on another array...   \n",
       "...        ...                                                ...   \n",
       "29695   python                                convert html to pdf   \n",
       "29696   python                                convert html to pdf   \n",
       "29697   python                                convert html to pdf   \n",
       "29698   python                                convert html to pdf   \n",
       "29699   python                                convert html to pdf   \n",
       "\n",
       "                                                     url  \n",
       "0      https://github.com/pyviz/holoviews/blob/ae0dd2...  \n",
       "1      https://github.com/google/prettytensor/blob/75...  \n",
       "2      https://github.com/rkday/nose2dep/blob/135a529...  \n",
       "3      https://github.com/Zitrax/nose-dep/blob/fd29c9...  \n",
       "4      https://github.com/lrq3000/pyFileFixity/blob/f...  \n",
       "...                                                  ...  \n",
       "29695  https://github.com/reingart/pyafipws/blob/ee87...  \n",
       "29696  https://github.com/doakey3/DashTable/blob/744c...  \n",
       "29697  https://github.com/chimera0/accel-brain-code/b...  \n",
       "29698  https://github.com/IndicoDataSolutions/IndicoI...  \n",
       "29699  https://github.com/mrstephenneal/pdfconduit/bl...  \n",
       "\n",
       "[29700 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the test results as a Pandas DataFrame\n",
    "test_es_results_df = pd.DataFrame(test_es_results)\n",
    "test_es_results_df = test_es_results_df.rename(columns={0: \"language\", 1: \"query\", 2: \"url\"})\n",
    "test_es_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "948cde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model predictions to a csv file\n",
    "test_es_results_df.to_csv(\"es_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af61f90",
   "metadata": {},
   "source": [
    "**Current best model:**\n",
    "- Using 200 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.24%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.42%\n",
    "NDCG:\n",
    "        python: 0.355\n",
    "NDCG (full ranking):\n",
    "        python: 0.203\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aefa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
