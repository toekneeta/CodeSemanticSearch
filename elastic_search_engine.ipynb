{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3745a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a29585",
   "metadata": {},
   "source": [
    "## Step 0: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f81255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 412178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22176\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 23107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_data = load_dataset(\"code_search_net\", \"python\")\n",
    "python_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6fdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data for Python code only\n",
    "data_train = python_data['train']\n",
    "data_train_snippet = data_train['whole_func_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd2334",
   "metadata": {},
   "source": [
    "## Step 1: Setting up ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5c9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "# es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580febd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the mappings (structure) for the python index\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        'repository_name': {\"type\": \"text\"}, \n",
    "        'func_path_in_repository': {\"type\": \"text\"}, \n",
    "        'func_name': {\"type\": \"text\"}, \n",
    "        'whole_func_string': {\"type\": \"text\"}, \n",
    "        'language': {\"type\": \"text\"}, \n",
    "        'func_code_string': {\"type\": \"text\"}, \n",
    "        'func_code_tokens': {\"type\": \"text\"}, \n",
    "        'func_documentation_string': {\"type\": \"text\"}, \n",
    "        'func_documentation_tokens': {\"type\": \"text\"}, \n",
    "        'split_name': {\"type\": \"text\"}, \n",
    "        'func_code_url': {\"type\": \"text\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "#analyzer settings\n",
    "analyzer_settings = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"code_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\"],\n",
    "                    \"char_filter\": [\"symbol_char_filter\"]\n",
    "                }\n",
    "            },\n",
    "            \"char_filter\": {\n",
    "                \"symbol_char_filter\": {\n",
    "                    \"type\": \"mapping\",\n",
    "                    \"mappings\": [\n",
    "                        \"_=> \",    # Replace underscore with space\n",
    "                        \";=>\",     # Remove semicolons\n",
    "                        \"{=>\",     # Remove opening curly braces\n",
    "                        \"}=>\",     # Remove closing curly braces\n",
    "                        \")=>\",\n",
    "                        \"(=>\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0796db5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The 'mappings' parameter is only serialized in the request body and can't be combined with the 'body' parameter. Either stop using the 'body' parameter and use keyword-arguments only or move the specified parameters into the 'body'. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\misaf\\Documents\\DSC 180A\\CodeSemanticSearch\\elastic_search_engine.ipynb Cell 9\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/misaf/Documents/DSC%20180A/CodeSemanticSearch/elastic_search_engine.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating the index python with the mappings above\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/misaf/Documents/DSC%20180A/CodeSemanticSearch/elastic_search_engine.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m es\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mcreate(index\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m\"\u001b[39;49m, mappings\u001b[39m=\u001b[39;49mmappings, body\u001b[39m=\u001b[39;49manalyzer_settings)\n",
      "File \u001b[1;32mc:\\Users\\misaf\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\elasticsearch\\client\\utils.py:244\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m     params_prose \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m(body_only_params_in_use))\n\u001b[0;32m    242\u001b[0m     plural_params \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(body_only_params_in_use) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m parameter\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m only serialized in the request body \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be combined with the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter. Either stop using the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter and use keyword-arguments only or move the specified \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameters into the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. See https://github.com/elastic/elasticsearch-py/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missues/1698 for more information\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m%\u001b[39m (\n\u001b[0;32m    251\u001b[0m             params_prose,\n\u001b[0;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m plural_params \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mare\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m plural_params \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mis\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    257\u001b[0m \u001b[39m# If there's no parameter overlap we still warn the user\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m# that the 'body' parameter is deprecated for this API.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m using_body_kwarg \u001b[39mand\u001b[39;00m body_params:\n",
      "\u001b[1;31mTypeError\u001b[0m: The 'mappings' parameter is only serialized in the request body and can't be combined with the 'body' parameter. Either stop using the 'body' parameter and use keyword-arguments only or move the specified parameters into the 'body'. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information"
     ]
    }
   ],
   "source": [
    "# Creating the index python with the mappings above\n",
    "# es.indices.create(index=\"python\", mappings=mappings, body=analyzer_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05441605",
   "metadata": {},
   "source": [
    "## Step 2: Adding Data into ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c5b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to read data into bulk_data: 185.27222657203674\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Creating a list of dictionaries with all the data to be added in to the ElasticSearch index\n",
    "bulk_data = []\n",
    "for i, row in enumerate(data_train):\n",
    "    bulk_data.append(\n",
    "        {\n",
    "            \"_index\": \"python\",\n",
    "            \"_id\": i,\n",
    "            \"_source\": {\n",
    "                \"repository_name\": row['repository_name'],\n",
    "                'func_path_in_repository': row['func_path_in_repository'], \n",
    "                'func_name': row['func_name'], \n",
    "                'whole_func_string': row['whole_func_string'], \n",
    "                'language': row['language'], \n",
    "                'func_code_string': row['func_code_string'], \n",
    "                'func_code_tokens': row['func_code_tokens'], \n",
    "                'func_documentation_string': row['func_documentation_string'], \n",
    "                'func_documentation_tokens': row['func_documentation_tokens'], \n",
    "                'split_name': row['split_name'], \n",
    "                'func_code_url': row['func_code_url']\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken to read data into bulk_data:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab0fbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Adding data into the index\n",
    "bulk(es, bulk_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken to add data into the index:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a544f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': '1701141985', 'timestamp': '03:26:25', 'count': '412178'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that all data has been read into the python index properly\n",
    "es.indices.refresh(index=\"python\")\n",
    "es.cat.count(index=\"python\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d55a3",
   "metadata": {},
   "source": [
    "## Step 3: Implementing the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query, k=10):\n",
    "    \"\"\"\n",
    "    Searches the data using ElasticSearch to find the k most similar documents to the query.\n",
    "    Returns a list of the k most similar functions, along with their GitHub URLs and their similarity scores to the query\n",
    "    \"\"\"\n",
    "\n",
    "    es_query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\n",
    "                            'repository_name',\n",
    "                            'func_path_in_repository',\n",
    "                            'func_name',\n",
    "                            'whole_func_string^3', #boost\n",
    "                            'language',\n",
    "                            'func_code_string',\n",
    "                            'func_code_tokens^2', # boost\n",
    "                            'func_documentation_string',\n",
    "                            'func_documentation_tokens',\n",
    "                            'split_name',\n",
    "                            'func_code_url'\n",
    "                        ],\n",
    "                        \"phrase_slop\": 2  # allows for flexibility in phrase matching\n",
    "                    }\n",
    "                },\n",
    "                # \"should\": [\n",
    "                #     {\"match_phrase\": {\"func_name\": {\"query\": query, \"boost\": 2}}},\n",
    "                #     {\"match_phrase\": {\"whole_func_string\": {\"query\": query, \"boost\": 3}}}\n",
    "                # ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": k\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=\"python\", body=es_query)\n",
    "    \n",
    "    results = []\n",
    "    # for each result, add the function name, the GitHub URL of the function, and the similarity score to the results list\n",
    "    for hit in response['hits']['hits']:\n",
    "        row = hit['_source']\n",
    "        results.append((row['func_name'], row['func_code_url'], hit['_score']))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c6e2b",
   "metadata": {},
   "source": [
    "## Step 4: Testing the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c0f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misaf\\AppData\\Local\\Temp\\ipykernel_21456\\4115504043.py:38: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  response = es.search(index=\"python\", body=es_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('unique',\n",
       "  'https://github.com/odlgroup/odl/blob/b8443f6aca90e191ba36c91d32253c5a36249a6c/odl/util/utility.py#L1573-L1611',\n",
       "  45.631638),\n",
       " ('generate_random_sframe',\n",
       "  'https://github.com/apple/turicreate/blob/74514c3f99e25b46f22c6e02977fe3da69221c2e/src/unity/python/turicreate/util/_sframe_generation.py#L13-L71',\n",
       "  44.05706),\n",
       " ('unique',\n",
       "  'https://github.com/limix/numpy-sugar/blob/4bdfa26913135c76ef3cd542a332f4e5861e948b/numpy_sugar/_array.py#L132-L149',\n",
       "  43.937515),\n",
       " ('BaseProvider.random_sample',\n",
       "  'https://github.com/joke2k/faker/blob/965824b61132e52d92d1a6ce470396dbbe01c96c/faker/providers/__init__.py#L243-L248',\n",
       "  43.868523),\n",
       " ('unique',\n",
       "  'https://github.com/dedupeio/dedupe/blob/9f7c9f84473a4bcacf0f2b11152d8ed3eb35d48b/dedupe/labeler.py#L383-L390',\n",
       "  42.598595)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"unique elements\"\n",
    "es_search(query, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3513f8459ec6',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'QXnwTBv3R4OXysjdMSv4NQ',\n",
       " 'version': {'number': '8.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': '09520b59b6bc1057340b55750186466ea715e30e',\n",
       "  'build_date': '2023-03-27T16:31:09.816451435Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.5.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misaf\\AppData\\Local\\Temp\\ipykernel_21456\\4115504043.py:38: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  response = es.search(index=\"python\", body=es_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('WHTTPCookieJar.import_header_text',\n",
       "  'https://github.com/a1ezzz/wasp-general/blob/1029839d33eb663f8dec76c1c46754d53c1de4a9/wasp_general/network/web/cookies.py#L316-L324',\n",
       "  46.9011),\n",
       " ('IIIFAuth.access_token',\n",
       "  'https://github.com/zimeon/iiif/blob/9d10018d01202fa2a76dfa61598dc6eca07b471f/iiif/auth.py#L257-L269',\n",
       "  46.719185),\n",
       " ('make_cookie',\n",
       "  'https://github.com/IdentityPython/pysaml2/blob/d3aa78eeb7d37c12688f783cb4db1c7263a14ad6/src/saml2/httputil.py#L320-L346',\n",
       "  45.47651)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create cookie\"\n",
    "es_search(query, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a282bb",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_query_python_es(query_list, k=10):\n",
    "    \"\"\"\n",
    "    Takes in a list of Python queries. Runs the search engine on those queries and returns\n",
    "    the top k results for that query\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    i = 1\n",
    "    \n",
    "    total_start = time.time()\n",
    "    for query in query_list:\n",
    "        # get top k results of query in our elastic search engine\n",
    "        query_search = es_search(query, k)\n",
    "        \n",
    "        # for each result of the query, add a row to test_results with\n",
    "        # the language (python), the query, and the GitHub Url to the result\n",
    "        for result in query_search:\n",
    "            # query_results = [\"python\", query, result[1]]\n",
    "            query_results = [\"python\", query, result[1], result[2]]\n",
    "            test_results.append(query_results)\n",
    "        \n",
    "        \n",
    "    total_end = time.time()\n",
    "    print(\"Time taken for all queries:\", total_end - total_start)\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59449427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the annotated test dataset and get only the Python queries\n",
    "test_queries = pd.read_csv('annotation_store.csv')\n",
    "python_queries = test_queries[test_queries['Language'] == 'Python']\n",
    "\n",
    "query_list = python_queries['Query'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac289884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misaf\\AppData\\Local\\Temp\\ipykernel_21456\\4115504043.py:38: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  response = es.search(index=\"python\", body=es_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for all queries: 50.9258668422699\n"
     ]
    }
   ],
   "source": [
    "# run the tests for the evaluation data\n",
    "test_es_results = run_test_query_python_es(query_list, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a805ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/pyviz/holoviews/blob/ae0dd2...</td>\n",
       "      <td>95.316956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/google/prettytensor/blob/75...</td>\n",
       "      <td>91.758850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/rkday/nose2dep/blob/135a529...</td>\n",
       "      <td>84.440155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/Zitrax/nose-dep/blob/fd29c9...</td>\n",
       "      <td>83.059630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>sorting multiple arrays based on another array...</td>\n",
       "      <td>https://github.com/bcbio/bcbio-nextgen/blob/6a...</td>\n",
       "      <td>80.840120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29695</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/acutesoftware/AIKIF/blob/fc...</td>\n",
       "      <td>30.825462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29696</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/PlaidWeb/Publ/blob/ce789363...</td>\n",
       "      <td>30.825462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29697</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/Phyks/libbmc/blob/9ef1a29d2...</td>\n",
       "      <td>30.756092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/DS-100/nb-to-gradescope/blo...</td>\n",
       "      <td>30.740334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29699</th>\n",
       "      <td>python</td>\n",
       "      <td>convert html to pdf</td>\n",
       "      <td>https://github.com/slinderman/pypolyagamma/blo...</td>\n",
       "      <td>30.740334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language                                              query  \\\n",
       "0       python  sorting multiple arrays based on another array...   \n",
       "1       python  sorting multiple arrays based on another array...   \n",
       "2       python  sorting multiple arrays based on another array...   \n",
       "3       python  sorting multiple arrays based on another array...   \n",
       "4       python  sorting multiple arrays based on another array...   \n",
       "...        ...                                                ...   \n",
       "29695   python                                convert html to pdf   \n",
       "29696   python                                convert html to pdf   \n",
       "29697   python                                convert html to pdf   \n",
       "29698   python                                convert html to pdf   \n",
       "29699   python                                convert html to pdf   \n",
       "\n",
       "                                                     url      score  \n",
       "0      https://github.com/pyviz/holoviews/blob/ae0dd2...  95.316956  \n",
       "1      https://github.com/google/prettytensor/blob/75...  91.758850  \n",
       "2      https://github.com/rkday/nose2dep/blob/135a529...  84.440155  \n",
       "3      https://github.com/Zitrax/nose-dep/blob/fd29c9...  83.059630  \n",
       "4      https://github.com/bcbio/bcbio-nextgen/blob/6a...  80.840120  \n",
       "...                                                  ...        ...  \n",
       "29695  https://github.com/acutesoftware/AIKIF/blob/fc...  30.825462  \n",
       "29696  https://github.com/PlaidWeb/Publ/blob/ce789363...  30.825462  \n",
       "29697  https://github.com/Phyks/libbmc/blob/9ef1a29d2...  30.756092  \n",
       "29698  https://github.com/DS-100/nb-to-gradescope/blo...  30.740334  \n",
       "29699  https://github.com/slinderman/pypolyagamma/blo...  30.740334  \n",
       "\n",
       "[29700 rows x 4 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the test results as a Pandas DataFrame\n",
    "test_es_results_df = pd.DataFrame(test_es_results)\n",
    "test_es_results_df.columns=['language', 'query', 'url', 'score']\n",
    "test_es_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model predictions to a csv file\n",
    "out = test_es_results_df[['language', 'query', 'url']]\n",
    "out.to_csv(\"es_model_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af61f90",
   "metadata": {},
   "source": [
    "**Simple Model (query_string search):**\n",
    "- Using 200 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.24%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.42%\n",
    "NDCG:\n",
    "        python: 0.355\n",
    "NDCG (full ranking):\n",
    "        python: 0.203\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved Model (field boosting + analyzer)**\n",
    "- Using 300 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.75%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.76%\n",
    "NDCG:\n",
    "        python: 0.373\n",
    "NDCG (full ranking):\n",
    "        python: 0.196\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved Model (field boosting + analyzer with 'should' statement removed)**\n",
    "- Using 300 top results from ElasticSearch engine\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 31.75%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 32.76%\n",
    "NDCG:\n",
    "        python: 0.367\n",
    "NDCG (full ranking):\n",
    "        python: 0.202\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LTR with LGBMRanker\n",
    "reference: https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in relevance scores and creating a merged dataset\n",
    "relevance_scores = pd.read_csv(\"annotation_store.csv\")\n",
    "\n",
    "#only working with Python\n",
    "python_rs = relevance_scores[relevance_scores['Language']=='Python']\n",
    "\n",
    "#merging and dropping irrelevant columns\n",
    "merged_scores = pd.merge(test_es_results_df, python_rs,  how='left', left_on=['query','url'], right_on = ['Query','GitHubUrl'])\n",
    "merged_scores = merged_scores.drop(columns=['Language', 'Query', 'GitHubUrl', 'Notes'])\n",
    "\n",
    "#search results that were not in the relevance csv get a relevance score of 0\n",
    "merged_scores['Relevance'] = merged_scores['Relevance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# need to have queries grouped together for our ranking model\n",
    "merged_scores = merged_scores.sort_values(by=[\"query\"], ascending=[True])\n",
    "\n",
    "# our feature will be the relevance score our es model returns\n",
    "X = merged_scores[['score']]\n",
    "y = merged_scores['Relevance']\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "train_groups = merged_scores.iloc[:len(X_train)].groupby('query').size().to_numpy()\n",
    "test_groups = merged_scores.iloc[len(X_train):].groupby('query').size().to_numpy()\n",
    "\n",
    "#checking lengths match up\n",
    "assert len(X_train) == sum(train_groups)\n",
    "assert len(X_test) == sum(test_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 27051, number of used features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(metric='ndcg', objective='lambdarank')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRanker\n",
    "# create model\n",
    "model = LGBMRanker(objective=\"lambdarank\", metric=\"ndcg\")\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train, y_train, group=train_groups, eval_set=[(X_test,y_test)],eval_group=[test_groups],eval_metric=['ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using the Model to Edit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>adjusted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/kalefranz/auxlib/blob/6ff2d...</td>\n",
       "      <td>51.046204</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.631907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/wbond/asn1crypto/blob/ecda2...</td>\n",
       "      <td>28.781193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/konomae/lastpass-python/blo...</td>\n",
       "      <td>28.841965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/BD2KGenomics/protect/blob/0...</td>\n",
       "      <td>28.895275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>python</td>\n",
       "      <td>aes encryption</td>\n",
       "      <td>https://github.com/saltstack/salt/blob/e8541fd...</td>\n",
       "      <td>29.012390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>python</td>\n",
       "      <td>write csv</td>\n",
       "      <td>https://github.com/davidhuser/dhis2.py/blob/78...</td>\n",
       "      <td>28.168568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.461132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>python</td>\n",
       "      <td>write csv</td>\n",
       "      <td>https://github.com/mrstephenneal/databasetools...</td>\n",
       "      <td>28.156490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.461132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>python</td>\n",
       "      <td>write csv</td>\n",
       "      <td>https://github.com/dfm/casjobs/blob/1cc3f5511c...</td>\n",
       "      <td>28.141950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.461132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12953</th>\n",
       "      <td>python</td>\n",
       "      <td>write csv</td>\n",
       "      <td>https://github.com/xflr6/concepts/blob/2801b27...</td>\n",
       "      <td>28.366123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12754</th>\n",
       "      <td>python</td>\n",
       "      <td>write csv</td>\n",
       "      <td>https://github.com/rvswift/EB/blob/341880b79fa...</td>\n",
       "      <td>50.175840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.682216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30057 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language           query  \\\n",
       "3961    python  aes encryption   \n",
       "4151    python  aes encryption   \n",
       "4150    python  aes encryption   \n",
       "4149    python  aes encryption   \n",
       "4148    python  aes encryption   \n",
       "...        ...             ...   \n",
       "12958   python       write csv   \n",
       "12959   python       write csv   \n",
       "12960   python       write csv   \n",
       "12953   python       write csv   \n",
       "12754   python       write csv   \n",
       "\n",
       "                                                     url      score  \\\n",
       "3961   https://github.com/kalefranz/auxlib/blob/6ff2d...  51.046204   \n",
       "4151   https://github.com/wbond/asn1crypto/blob/ecda2...  28.781193   \n",
       "4150   https://github.com/konomae/lastpass-python/blo...  28.841965   \n",
       "4149   https://github.com/BD2KGenomics/protect/blob/0...  28.895275   \n",
       "4148   https://github.com/saltstack/salt/blob/e8541fd...  29.012390   \n",
       "...                                                  ...        ...   \n",
       "12958  https://github.com/davidhuser/dhis2.py/blob/78...  28.168568   \n",
       "12959  https://github.com/mrstephenneal/databasetools...  28.156490   \n",
       "12960  https://github.com/dfm/casjobs/blob/1cc3f5511c...  28.141950   \n",
       "12953  https://github.com/xflr6/concepts/blob/2801b27...  28.366123   \n",
       "12754  https://github.com/rvswift/EB/blob/341880b79fa...  50.175840   \n",
       "\n",
       "       Relevance  adjusted_score  \n",
       "3961         3.0        0.631907  \n",
       "4151         0.0       -6.101293  \n",
       "4150         0.0       -6.101293  \n",
       "4149         0.0       -6.101293  \n",
       "4148         0.0       -6.101293  \n",
       "...          ...             ...  \n",
       "12958        0.0       -1.461132  \n",
       "12959        0.0       -1.461132  \n",
       "12960        0.0       -1.461132  \n",
       "12953        0.0       -6.101293  \n",
       "12754        2.0       -0.682216  \n",
       "\n",
       "[30057 rows x 6 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the model to predict an adjusted score\n",
    "merged_scores['adjusted_score'] = model.predict(merged_scores[['score']])\n",
    "merged_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the results that have an adjusted score above the threshold (found through trial and error)\n",
    "thresh = -0.75\n",
    "new_preds = merged_scores[(merged_scores['adjusted_score'] >= thresh)]\n",
    "\n",
    "#output results\n",
    "new_preds[['language', 'query', 'url']].to_csv('ltr_es_model_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold = -0.75\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 20.32%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 21.39%\n",
    "NDCG:\n",
    "        python: 0.438\n",
    "NDCG (full ranking):\n",
    "        python: 0.241\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold = -5\n",
    "```\n",
    "% of URLs in predictions that exist in the annotation dataset:\n",
    "        python: 30.84%\n",
    "% of URLs in predictions that exist in the annotation dataset (avg relevance > 0):\n",
    "        python: 31.97%\n",
    "NDCG:\n",
    "        python: 0.583\n",
    "NDCG (full ranking):\n",
    "        python: 0.213\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
